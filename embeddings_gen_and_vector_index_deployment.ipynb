{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b98b62-87dd-475f-a439-e9a96a897838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = 1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f768799c-2ba0-4f5a-bade-70e7b4a039b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: pypdf2\n",
      "Successfully installed pypdf2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55552c33-384b-41c6-b9c7-0646b668bb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "import PyPDF2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a1c065-e8ae-4301-a822-9a299315fd06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project=\"robust-habitat-439810-p4\"\n",
    "location=\"us-central1\"\n",
    "MODEL_NAME = \"text-embedding-preview-0815\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718921bd-0b98-4d21-a666-d7455a69e190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf_path=\"lakeside_handbook.pdf\"\n",
    "bucket_name = \"sukrit_bucket_1\"\n",
    "embed_file_path = \"lakeside_embeddings.json\"\n",
    "sentence_file_path = \"lakeside_sentences.json\"\n",
    "index_name=\"lakeside_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ced2c5db-4cad-4f2e-90f9-0c9410fca762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_sentences_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            if page.extract_text() is not None:\n",
    "                text += page.extract_text() + \" \"\n",
    "    sentences = [sentence.strip() for sentence in text.split('. ') if sentence.strip()]\n",
    "    return sentences\n",
    "\n",
    "def generate_text_embeddings(sentences) -> list: \n",
    "  aiplatform.init(project=project,location=location)\n",
    "  model = TextEmbeddingModel.from_pretrained(MODEL_NAME)  # Change to a model you have access to\n",
    "  # model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\n",
    "  embeddings = model.get_embeddings(sentences)\n",
    "  vectors = [embedding.values for embedding in embeddings]\n",
    "  return vectors\n",
    "\n",
    "def generate_and_save_embeddings(pdf_path, sentence_file_path, embed_file_path):\n",
    "    def clean_text(text):\n",
    "        cleaned_text = re.sub(r'\\u2022', '', text)  # Remove bullet points\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Remove extra whitespaces and strip\n",
    "        return cleaned_text\n",
    "    \n",
    "    sentences = extract_sentences_from_pdf(pdf_path)\n",
    "    if sentences:\n",
    "        embeddings = generate_text_embeddings(sentences)\n",
    "        \n",
    "        with open(embed_file_path, 'w') as embed_file, open(sentence_file_path, 'w') as sentence_file:\n",
    "            for sentence, embedding in zip(sentences, embeddings):\n",
    "                cleaned_sentence = clean_text(sentence)\n",
    "                id = str(uuid.uuid4())\n",
    "                \n",
    "                embed_item = {\"id\": id, \"embedding\": embedding}\n",
    "                sentence_item = {\"id\": id, \"sentence\": cleaned_sentence}\n",
    "                \n",
    "                json.dump(sentence_item, sentence_file)\n",
    "                sentence_file.write('\\n') \n",
    "                json.dump(embed_item, embed_file)\n",
    "                embed_file.write('\\n')\n",
    "\n",
    "# def upload_file(bucket_name,file_path):\n",
    "#     storage_client = storage.Client()\n",
    "#     bucket = storage_client.create_bucket(bucket_name,location=location)\n",
    "#     blob = bucket.blob(file_path)\n",
    "#     blob.upload_from_filename(file_path)\n",
    "\n",
    "def upload_file(bucket_name, file_path, location=\"us-central1\", prefix=\"\"):\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Check if the bucket already exists\n",
    "    try:\n",
    "        bucket = storage_client.get_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except NotFound:\n",
    "        bucket = storage_client.create_bucket(bucket_name, location=location)\n",
    "        print(f\"Bucket {bucket_name} created.\")\n",
    "\n",
    "    # Create a blob and upload the file\n",
    "    blob = bucket.blob(file_path)\n",
    "    blob.upload_from_filename(file_path)\n",
    "    print(f\"File {file_path} uploaded to {bucket_name}.\")\n",
    "\n",
    "    # Return the full URI of the uploaded file\n",
    "    file_uri = f\"gs://{bucket_name}/{file_path}\"\n",
    "    return file_uri\n",
    "\n",
    "\n",
    "    \n",
    "# def create_vector_index(bucket_name, index_name):\n",
    "#     lakeside_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "#     display_name = index_name,\n",
    "#     contents_delta_uri = \"gs://\"+bucket_name,\n",
    "#     dimensions = 768,\n",
    "#     approximate_neighbors_count = 10,\n",
    "#     )\n",
    "                  \n",
    "#     lakeside_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "#     display_name = index_name,\n",
    "#     public_endpoint_enabled = True\n",
    "#     )                      \n",
    "\n",
    "#     lakeside_index_endpoint.deploy_index(\n",
    "#     index = lakeside_index, deployed_index_id = index_name\n",
    "#     )\n",
    "\n",
    "def create_vector_index(bucket_name, index_name, machine_type=\"n1-standard-16\", min_replica_count=1, max_replica_count=1):\n",
    "    # Create the Matching Engine Index\n",
    "    lakeside_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=index_name,\n",
    "        contents_delta_uri=\"gs://\" + bucket_name, # Will be the uri of the embeddings file \n",
    "        dimensions=768,\n",
    "        approximate_neighbors_count=10,\n",
    "    )\n",
    "                  \n",
    "    # Create the Matching Engine Index Endpoint\n",
    "    lakeside_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=index_name,\n",
    "        public_endpoint_enabled=True\n",
    "    )                      \n",
    "\n",
    "    # Deploy the index to the endpoint with compatible machine type and replica counts\n",
    "    lakeside_index_endpoint.deploy_index(\n",
    "        index=lakeside_index,\n",
    "        deployed_index_id=index_name,\n",
    "        machine_type=machine_type,\n",
    "        min_replica_count=min_replica_count,\n",
    "        max_replica_count=max_replica_count\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1940b521-8679-4766-8cef-4c237d02a810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/1087248591320/locations/us-central1/indexes/5029654368610156544/operations/6680546510502887424\n",
      "MatchingEngineIndex created. Resource name: projects/1087248591320/locations/us-central1/indexes/5029654368610156544\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/1087248591320/locations/us-central1/indexes/5029654368610156544')\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/1087248591320/locations/us-central1/indexEndpoints/6361453220916625408/operations/4936246079826952192\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/1087248591320/locations/us-central1/indexEndpoints/6361453220916625408\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/1087248591320/locations/us-central1/indexEndpoints/6361453220916625408')\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/1087248591320/locations/us-central1/indexEndpoints/6361453220916625408\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/1087248591320/locations/us-central1/indexEndpoints/6361453220916625408/operations/3412340555915460608\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/1087248591320/locations/us-central1/indexEndpoints/6361453220916625408\n"
     ]
    }
   ],
   "source": [
    "# generate_and_save_embeddings(pdf_path,sentence_file_path,embed_file_path)\n",
    "# upload_file(bucket_name,embed_file_path)\n",
    "create_vector_index(bucket_name, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a88c11fc-c346-44af-aa3f-e0a40a278359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Working - Sample codebase to generate embeddings\n",
    "\n",
    "# from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "# MODEL_NAME = \"text-embedding-preview-0815\"\n",
    "# DIMENSIONALITY = 256\n",
    "\n",
    "\n",
    "# def embed_text(\n",
    "#     texts: list[str] = [\"Retrieve a function that adds two numbers\"],\n",
    "#     task: str = \"CODE_RETRIEVAL_QUERY\",\n",
    "#     model_name: str = \"text-embedding-preview-0815\",\n",
    "#     dimensionality: int | None = 256,\n",
    "# ) -> list[list[float]]:\n",
    "#     \"\"\"Embeds texts with a pre-trained, foundational model.\"\"\"\n",
    "#     model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "#     inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "#     kwargs = dict(output_dimensionality=dimensionality) if dimensionality else {}\n",
    "#     embeddings = model.get_embeddings(inputs, **kwargs)\n",
    "#     # Example response:\n",
    "#     # [[0.025890009477734566, -0.05553026497364044, 0.006374752148985863,...],\n",
    "#     return [embedding.values for embedding in embeddings]\n",
    "\n",
    "# texts = [\"Retrieve a function that adds two numbers\"]\n",
    "# task = \"CODE_RETRIEVAL_QUERY\"\n",
    "# code_block_embeddings = embed_text(\n",
    "#     texts=texts, task=task, model_name=MODEL_NAME, dimensionality=DIMENSIONALITY\n",
    "# )\n",
    "\n",
    "# # Embeds code retrieval with a pre-trained, foundational model.\n",
    "# # Using this function to calculate the embedding for query.\n",
    "# texts = [\n",
    "#     \"def func(a, b): return a + b\",\n",
    "#     \"def func(a, b): return a - b\",\n",
    "#     \"def func(a, b): return (a ** 2 + b ** 2) ** 0.5\",\n",
    "# ]\n",
    "# task = \"RETRIEVAL_DOCUMENT\"\n",
    "# code_query_embeddings = embed_text(\n",
    "#     texts=texts, task=task, model_name=MODEL_NAME, dimensionality=DIMENSIONALITY\n",
    "# )\n",
    "# print(code_query_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31abd89-4872-4549-aea2-bbd500494d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
